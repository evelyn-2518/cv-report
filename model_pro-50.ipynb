{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18d5008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T09:09:33.437343Z",
     "iopub.status.busy": "2025-11-19T09:09:33.436562Z",
     "iopub.status.idle": "2025-11-19T09:09:35.260564Z",
     "shell.execute_reply": "2025-11-19T09:09:35.258947Z",
     "shell.execute_reply.started": "2025-11-19T09:09:33.437282Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from collections import Counter\n",
    "import random\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b4528b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T09:09:44.894828Z",
     "iopub.status.busy": "2025-11-19T09:09:44.894454Z",
     "iopub.status.idle": "2025-11-19T09:09:45.005220Z",
     "shell.execute_reply": "2025-11-19T09:09:45.002633Z",
     "shell.execute_reply.started": "2025-11-19T09:09:44.894805Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "å¾è³‡æ–™å¤¾ä¸­é‡å»ºæ¨™ç±¤æ˜ å°„ï¼Œå…± 4600 å€‹é¡åˆ¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "# --- A. æª”æ¡ˆè·¯å¾‘èˆ‡å¸¸æ•¸è¨­å®š (æŒ‡å‘æ‚¨çš„å·¥ä½œç›®éŒ„) ---\n",
    "DATASET_ROOT = \".\"\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATASET_ROOT, \"train\", \"images\")\n",
    "VAL_IMAGES_DIR = os.path.join(DATASET_ROOT, \"val\", \"images\")\n",
    "WEIGHTS_SAVE_PATH = 'baseline_model.pth' \n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ResNet50 æ¨™æº–åƒæ•¸\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "# --- B. å»ºç«‹å…¨åŸŸæ¨™ç±¤æ˜ å°„\n",
    "def build_label_map(root_dir: str) -> Tuple[List[str], dict]:\n",
    "    \"\"\"æƒææ‰€æœ‰åˆ†å€ï¼Œå»ºç«‹ item_id åˆ° 0~4599 æ•¸å­—æ¨™ç±¤çš„æ˜ å°„\"\"\"\n",
    "    all_item_ids = set()\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_dir = os.path.join(root_dir, split, \"images\")\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "        for img_file in os.listdir(split_dir):\n",
    "            if img_file.endswith('.jpg'):\n",
    "                item_id = img_file.split(\"_\")[0]\n",
    "                all_item_ids.add(item_id)\n",
    "\n",
    "    # å»ºç«‹ item_id å­—ç¬¦ä¸²åˆ°æ•´æ•¸æ¨™ç±¤çš„æ˜ å°„\n",
    "    sorted_ids = sorted(list(all_item_ids))\n",
    "    item_to_idx = {item_id: idx for idx, item_id in enumerate(sorted_ids)}\n",
    "\n",
    "    return sorted_ids, item_to_idx\n",
    "\n",
    "ITEM_ID_LIST, ITEM_TO_IDX = build_label_map(DATASET_ROOT)\n",
    "NUM_CLASSES = len(ITEM_ID_LIST)\n",
    "print(f\"å¾è³‡æ–™å¤¾ä¸­é‡å»ºæ¨™ç±¤æ˜ å°„ï¼Œå…± {NUM_CLASSES} å€‹é¡åˆ¥ã€‚\")\n",
    "\n",
    "\n",
    "# --- C. DeepFashionRetrievalDataset Class\n",
    "class FolderBasedRetrievalDataset(Dataset):\n",
    "    \"\"\"ç›´æ¥å¾è³‡æ–™å¤¾è®€å–æª”æ¡ˆæ¸…å–®ï¼Œä¸¦å‹•æ…‹æå–æ¨™ç±¤ã€‚\"\"\"\n",
    "    def __init__(self, images_dir: str, item_to_idx: dict, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.item_to_idx = item_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        # 1. æå–æ¨™ç±¤\n",
    "        item_id = img_name.split(\"_\")[0]\n",
    "        label = self.item_to_idx[item_id] # å–å¾— 0~4599 çš„æ•´æ•¸æ¨™ç±¤\n",
    "\n",
    "        # 2. è¼‰å…¥åœ–åƒ\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # 3. é è™•ç†\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# --- D. Transforms (ResNet50) \n",
    "# ç¢ºä¿ TRAIN å’Œ VAL ä½¿ç”¨ä¸åŒçš„ transforms\n",
    "TRAIN_TRANSFORMS = transforms.Compose([\n",
    "    transforms.Resize(256),              \n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8,1.0)), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD) \n",
    "])\n",
    "\n",
    "VAL_TEST_TRANSFORMS = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMAGE_SIZE), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d8867d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T09:09:48.046853Z",
     "iopub.status.busy": "2025-11-19T09:09:48.046081Z",
     "iopub.status.idle": "2025-11-19T09:09:48.116944Z",
     "shell.execute_reply": "2025-11-19T09:09:48.114508Z",
     "shell.execute_reply.started": "2025-11-19T09:09:48.046768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¨ˆç®— WeightedRandomSampler æ¬Šé‡...\n",
      "è¨“ç·´é›†åœ–åƒæ•¸: 13752ã€‚é©—è­‰é›†åœ–åƒæ•¸: 13752\n",
      "âœ… DataLoader èˆ‡ WeightedRandomSampler å·²é‡æ–°å»ºç«‹ã€‚\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# å€å¡Š 2ï¼šDataLoader å»ºç«‹\n",
    "# =======================================================\n",
    "\n",
    "# å»ºç«‹ Dataset\n",
    "train_dataset = FolderBasedRetrievalDataset(TRAIN_IMAGES_DIR, ITEM_TO_IDX, TRAIN_TRANSFORMS)\n",
    "val_dataset = FolderBasedRetrievalDataset(VAL_IMAGES_DIR, ITEM_TO_IDX, VAL_TEST_TRANSFORMS)\n",
    "\n",
    "# --- E. é‡æ–°è¨ˆç®— WeightedRandomSampler (è™•ç†è³‡æ–™ä¸å¹³è¡¡)\n",
    "print(\"æ­£åœ¨è¨ˆç®— WeightedRandomSampler æ¬Šé‡...\")\n",
    "train_labels = [train_dataset.item_to_idx[f.split(\"_\")[0]] for f in train_dataset.image_files] \n",
    "class_sample_count = np.bincount(train_labels)\n",
    "class_sample_count[class_sample_count==0] = 1 \n",
    "weights = 1.0 / class_sample_count\n",
    "sample_weights = np.array([weights[l] for l in train_labels])\n",
    "sample_weights = torch.DoubleTensor(sample_weights)\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                 num_samples=len(sample_weights),\n",
    "                                 replacement=True)\n",
    "\n",
    "# --- F. å»ºç«‹ DataLoader ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"è¨“ç·´é›†åœ–åƒæ•¸: {len(train_dataset)}ã€‚é©—è­‰é›†åœ–åƒæ•¸: {len(val_dataset)}\")\n",
    "print(\"âœ… DataLoader èˆ‡ WeightedRandomSampler å·²é‡æ–°å»ºç«‹ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f017b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T09:10:05.267161Z",
     "iopub.status.busy": "2025-11-19T09:10:05.266817Z",
     "iopub.status.idle": "2025-11-19T10:42:47.184490Z",
     "shell.execute_reply": "2025-11-19T10:42:47.183654Z",
     "shell.execute_reply.started": "2025-11-19T09:10:05.267139Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- é–‹å§‹è¨“ç·´ (Epochs: 50, Patience: 5) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:15<00:00,  5.69it/s]\n",
      "Epoch 1 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:44<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 1, Train Loss: 8.4232, Train Acc: 0.0007, Val Loss: 8.4097, Val Acc: 0.0007\n",
      "*** Val Loss æ”¹å–„ (8.4097)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.85it/s]\n",
      "Epoch 2 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:42<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 2, Train Loss: 8.3178, Train Acc: 0.0039, Val Loss: 8.2850, Val Acc: 0.0025\n",
      "*** Val Loss æ”¹å–„ (8.2850)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.78it/s]\n",
      "Epoch 3 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:47<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 3, Train Loss: 8.0280, Train Acc: 0.0119, Val Loss: 7.9717, Val Acc: 0.0111\n",
      "*** Val Loss æ”¹å–„ (7.9717)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:09<00:00,  6.14it/s]\n",
      "Epoch 4 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 4, Train Loss: 7.5499, Train Acc: 0.0500, Val Loss: 7.4759, Val Acc: 0.0359\n",
      "*** Val Loss æ”¹å–„ (7.4759)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.66it/s]\n",
      "Epoch 5 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 5, Train Loss: 6.9098, Train Acc: 0.1230, Val Loss: 6.8413, Val Acc: 0.0740\n",
      "*** Val Loss æ”¹å–„ (6.8413)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.75it/s]\n",
      "Epoch 6 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:42<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 6, Train Loss: 6.2304, Train Acc: 0.2062, Val Loss: 6.2389, Val Acc: 0.1219\n",
      "*** Val Loss æ”¹å–„ (6.2389)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:06<00:00,  6.44it/s]\n",
      "Epoch 7 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:41<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 7, Train Loss: 5.5138, Train Acc: 0.3075, Val Loss: 5.5976, Val Acc: 0.1641\n",
      "*** Val Loss æ”¹å–„ (5.5976)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:06<00:00,  6.48it/s]\n",
      "Epoch 8 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 8, Train Loss: 4.8437, Train Acc: 0.4007, Val Loss: 5.0683, Val Acc: 0.2245\n",
      "*** Val Loss æ”¹å–„ (5.0683)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:08<00:00,  6.32it/s]\n",
      "Epoch 9 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:48<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 9, Train Loss: 4.2186, Train Acc: 0.4884, Val Loss: 4.5739, Val Acc: 0.2820\n",
      "*** Val Loss æ”¹å–„ (4.5739)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.76it/s]\n",
      "Epoch 10 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 10, Train Loss: 3.6737, Train Acc: 0.5677, Val Loss: 4.1405, Val Acc: 0.3358\n",
      "*** Val Loss æ”¹å–„ (4.1405)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.86it/s]\n",
      "Epoch 11 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 11, Train Loss: 3.1516, Train Acc: 0.6416, Val Loss: 3.7671, Val Acc: 0.3837\n",
      "*** Val Loss æ”¹å–„ (3.7671)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:13<00:00,  5.87it/s]\n",
      "Epoch 12 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:45<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 12, Train Loss: 2.7460, Train Acc: 0.6936, Val Loss: 3.4650, Val Acc: 0.4272\n",
      "*** Val Loss æ”¹å–„ (3.4650)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.79it/s]\n",
      "Epoch 13 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:43<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 13, Train Loss: 2.3657, Train Acc: 0.7472, Val Loss: 3.1560, Val Acc: 0.4678\n",
      "*** Val Loss æ”¹å–„ (3.1560)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.86it/s]\n",
      "Epoch 14 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:41<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 14, Train Loss: 2.0721, Train Acc: 0.7802, Val Loss: 2.9109, Val Acc: 0.5137\n",
      "*** Val Loss æ”¹å–„ (2.9109)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:13<00:00,  5.87it/s]\n",
      "Epoch 15 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:44<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 15, Train Loss: 1.7929, Train Acc: 0.8157, Val Loss: 2.7018, Val Acc: 0.5433\n",
      "*** Val Loss æ”¹å–„ (2.7018)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.82it/s]\n",
      "Epoch 16 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:42<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 16, Train Loss: 1.5617, Train Acc: 0.8365, Val Loss: 2.4672, Val Acc: 0.5702\n",
      "*** Val Loss æ”¹å–„ (2.4672)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.89it/s]\n",
      "Epoch 17 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:53<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 17, Train Loss: 1.3672, Train Acc: 0.8647, Val Loss: 2.3458, Val Acc: 0.5952\n",
      "*** Val Loss æ”¹å–„ (2.3458)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:05<00:00,  6.54it/s]\n",
      "Epoch 18 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:45<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 18, Train Loss: 1.1892, Train Acc: 0.8829, Val Loss: 2.1848, Val Acc: 0.6281\n",
      "*** Val Loss æ”¹å–„ (2.1848)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.65it/s]\n",
      "Epoch 19 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 19, Train Loss: 1.0651, Train Acc: 0.8954, Val Loss: 1.9844, Val Acc: 0.6501\n",
      "*** Val Loss æ”¹å–„ (1.9844)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:12<00:00,  5.93it/s]\n",
      "Epoch 20 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:47<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 20, Train Loss: 0.9399, Train Acc: 0.9108, Val Loss: 1.9262, Val Acc: 0.6688\n",
      "*** Val Loss æ”¹å–„ (1.9262)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:05<00:00,  6.56it/s]\n",
      "Epoch 21 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:41<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 21, Train Loss: 0.8324, Train Acc: 0.9216, Val Loss: 1.7716, Val Acc: 0.6875\n",
      "*** Val Loss æ”¹å–„ (1.7716)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.76it/s]\n",
      "Epoch 22 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 22, Train Loss: 0.7469, Train Acc: 0.9286, Val Loss: 1.6839, Val Acc: 0.7041\n",
      "*** Val Loss æ”¹å–„ (1.6839)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:17<00:00,  5.56it/s]\n",
      "Epoch 23 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 23, Train Loss: 0.6615, Train Acc: 0.9367, Val Loss: 1.5947, Val Acc: 0.7202\n",
      "*** Val Loss æ”¹å–„ (1.5947)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:06<00:00,  6.43it/s]\n",
      "Epoch 24 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 24, Train Loss: 0.5949, Train Acc: 0.9458, Val Loss: 1.5057, Val Acc: 0.7320\n",
      "*** Val Loss æ”¹å–„ (1.5057)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:01<00:00,  7.02it/s]\n",
      "Epoch 25 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:50<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 25, Train Loss: 0.5346, Train Acc: 0.9511, Val Loss: 1.3891, Val Acc: 0.7525\n",
      "*** Val Loss æ”¹å–„ (1.3891)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:07<00:00,  6.37it/s]\n",
      "Epoch 26 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:41<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 26, Train Loss: 0.4871, Train Acc: 0.9567, Val Loss: 1.3207, Val Acc: 0.7643\n",
      "*** Val Loss æ”¹å–„ (1.3207)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.68it/s]\n",
      "Epoch 27 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 27, Train Loss: 0.4331, Train Acc: 0.9615, Val Loss: 1.2480, Val Acc: 0.7785\n",
      "*** Val Loss æ”¹å–„ (1.2480)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:08<00:00,  6.32it/s]\n",
      "Epoch 28 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:51<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 28, Train Loss: 0.3964, Train Acc: 0.9642, Val Loss: 1.1583, Val Acc: 0.7948\n",
      "*** Val Loss æ”¹å–„ (1.1583)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.65it/s]\n",
      "Epoch 29 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:41<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 29, Train Loss: 0.3541, Train Acc: 0.9687, Val Loss: 1.1252, Val Acc: 0.7952\n",
      "*** Val Loss æ”¹å–„ (1.1252)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:05<00:00,  6.61it/s]\n",
      "Epoch 30 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 30, Train Loss: 0.3206, Train Acc: 0.9718, Val Loss: 1.0472, Val Acc: 0.8051\n",
      "*** Val Loss æ”¹å–„ (1.0472)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:15<00:00,  5.67it/s]\n",
      "Epoch 31 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:47<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 31, Train Loss: 0.2919, Train Acc: 0.9738, Val Loss: 0.9928, Val Acc: 0.8120\n",
      "*** Val Loss æ”¹å–„ (0.9928)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.80it/s]\n",
      "Epoch 32 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 32, Train Loss: 0.2706, Train Acc: 0.9762, Val Loss: 0.9550, Val Acc: 0.8242\n",
      "*** Val Loss æ”¹å–„ (0.9550)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.84it/s]\n",
      "Epoch 33 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:46<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 33, Train Loss: 0.2377, Train Acc: 0.9805, Val Loss: 0.9013, Val Acc: 0.8325\n",
      "*** Val Loss æ”¹å–„ (0.9013)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:12<00:00,  5.96it/s]\n",
      "Epoch 34 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 34, Train Loss: 0.2306, Train Acc: 0.9779, Val Loss: 0.8527, Val Acc: 0.8408\n",
      "*** Val Loss æ”¹å–„ (0.8527)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.70it/s]\n",
      "Epoch 35 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:42<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 35, Train Loss: 0.2086, Train Acc: 0.9794, Val Loss: 0.8319, Val Acc: 0.8417\n",
      "*** Val Loss æ”¹å–„ (0.8319)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:05<00:00,  6.59it/s]\n",
      "Epoch 36 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:52<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 36, Train Loss: 0.1840, Train Acc: 0.9844, Val Loss: 0.8132, Val Acc: 0.8447\n",
      "*** Val Loss æ”¹å–„ (0.8132)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:10<00:00,  6.09it/s]\n",
      "Epoch 37 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:48<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 37, Train Loss: 0.1810, Train Acc: 0.9827, Val Loss: 0.7387, Val Acc: 0.8575\n",
      "*** Val Loss æ”¹å–„ (0.7387)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.91it/s]\n",
      "Epoch 38 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:45<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 38, Train Loss: 0.1552, Train Acc: 0.9873, Val Loss: 0.7532, Val Acc: 0.8514\n",
      "Val Loss æœªæ”¹å–„ (é€£çºŒ 1 å€‹é€±æœŸæœªæ”¹å–„).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:16<00:00,  5.60it/s]\n",
      "Epoch 39 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:44<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 39, Train Loss: 0.1482, Train Acc: 0.9855, Val Loss: 0.7009, Val Acc: 0.8638\n",
      "*** Val Loss æ”¹å–„ (0.7009)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:08<00:00,  6.31it/s]\n",
      "Epoch 40 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:41<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 40, Train Loss: 0.1380, Train Acc: 0.9869, Val Loss: 0.6575, Val Acc: 0.8709\n",
      "*** Val Loss æ”¹å–„ (0.6575)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:02<00:00,  6.85it/s]\n",
      "Epoch 41 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:46<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 41, Train Loss: 0.1271, Train Acc: 0.9876, Val Loss: 0.6219, Val Acc: 0.8733\n",
      "*** Val Loss æ”¹å–„ (0.6219)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:11<00:00,  6.05it/s]\n",
      "Epoch 42 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 42, Train Loss: 0.1195, Train Acc: 0.9872, Val Loss: 0.6281, Val Acc: 0.8738\n",
      "Val Loss æœªæ”¹å–„ (é€£çºŒ 1 å€‹é€±æœŸæœªæ”¹å–„).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:07<00:00,  6.34it/s]\n",
      "Epoch 43 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:39<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 43, Train Loss: 0.1049, Train Acc: 0.9902, Val Loss: 0.5995, Val Acc: 0.8793\n",
      "*** Val Loss æ”¹å–„ (0.5995)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:07<00:00,  6.38it/s]\n",
      "Epoch 44 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:50<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 44, Train Loss: 0.1054, Train Acc: 0.9899, Val Loss: 0.5660, Val Acc: 0.8846\n",
      "*** Val Loss æ”¹å–„ (0.5660)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.67it/s]\n",
      "Epoch 45 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:45<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 45, Train Loss: 0.0956, Train Acc: 0.9905, Val Loss: 0.5436, Val Acc: 0.8858\n",
      "*** Val Loss æ”¹å–„ (0.5436)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.80it/s]\n",
      "Epoch 46 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:40<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 46, Train Loss: 0.0863, Train Acc: 0.9921, Val Loss: 0.5142, Val Acc: 0.8922\n",
      "*** Val Loss æ”¹å–„ (0.5142)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:17<00:00,  5.57it/s]\n",
      "Epoch 47 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:49<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 47, Train Loss: 0.0844, Train Acc: 0.9911, Val Loss: 0.5062, Val Acc: 0.8917\n",
      "*** Val Loss æ”¹å–„ (0.5062)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:04<00:00,  6.71it/s]\n",
      "Epoch 48 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:46<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 48, Train Loss: 0.0756, Train Acc: 0.9929, Val Loss: 0.4815, Val Acc: 0.8989\n",
      "*** Val Loss æ”¹å–„ (0.4815)ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° baseline_model.pth ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.82it/s]\n",
      "Epoch 49 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:48<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 49, Train Loss: 0.0670, Train Acc: 0.9944, Val Loss: 0.4890, Val Acc: 0.8971\n",
      "Val Loss æœªæ”¹å–„ (é€£çºŒ 1 å€‹é€±æœŸæœªæ”¹å–„).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:10<00:00,  6.07it/s]\n",
      "Epoch 50 Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:42<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[çµæœ] Epoch 50, Train Loss: 0.0681, Train Acc: 0.9921, Val Loss: 0.4908, Val Acc: 0.8941\n",
      "Val Loss æœªæ”¹å–„ (é€£çºŒ 2 å€‹é€±æœŸæœªæ”¹å–„).\n",
      "\n",
      "è¨“ç·´æµç¨‹çµæŸã€‚\n",
      "\n",
      "âœ… è¨“ç·´å®Œæˆã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# å€å¡Š 3ï¼šBaseline æ¨¡å‹å®šç¾©èˆ‡è¨“ç·´åŸ·è¡Œ (æœ€çµ‚æ•´åˆç‰ˆ)\n",
    "# =======================================================\n",
    "\n",
    "# --- G. æ¨¡å‹å®šç¾©\n",
    "def build_baseline_model(num_classes: int) -> nn.Module:\n",
    "    model = resnet50(weights=ResNet50_Weights.DEFAULT) \n",
    "    num_ftrs = model.fc.in_features \n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "# --- H. è¨“ç·´å’Œä¿å­˜\n",
    "def train_and_save_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, \n",
    "                         num_epochs: int, learning_rate: float, patience: int):\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    \n",
    "    # Early Stopping è®Šæ•¸åˆå§‹åŒ–\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    print(f\"--- é–‹å§‹è¨“ç·´ (Epochs: {num_epochs}, Patience: {patience}) ---\")\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # -------------------- è¨“ç·´æ­¥é©Ÿ --------------------\n",
    "        model.train()\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch} Training\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # æº–ç¢ºç‡è¨ˆç®—\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # è¨ˆç®—è¨“ç·´çµæœ\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        \n",
    "        # -------------------- é©—è­‰æ­¥é©Ÿ --------------------\n",
    "        model.eval()\n",
    "        val_loss, val_corrects = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch} Validation\"):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                \n",
    "                # æº–ç¢ºç‡è¨ˆç®—\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # è¨ˆç®—é©—è­‰çµæœ\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        \n",
    "        # è¼¸å‡ºæŒ‡æ¨™\n",
    "        print(f\"\\n[çµæœ] Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")\n",
    "\n",
    "        \n",
    "        # -------------------- Early Stopping å’Œæ¨¡å‹ä¿å­˜ --------------------\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0 # Val Loss æ”¹å–„ï¼Œé‡ç½®è¨ˆæ•¸å™¨\n",
    "            \n",
    "            # åƒ…åœ¨ Val Loss æœ€ä½³æ™‚ä¿å­˜æ¨¡å‹\n",
    "            torch.save(model.state_dict(), WEIGHTS_SAVE_PATH)\n",
    "            print(f\"*** Val Loss æ”¹å–„ ({best_val_loss:.4f})ï¼Œæ¨¡å‹æ¬Šé‡å·²ä¿å­˜åˆ° {WEIGHTS_SAVE_PATH} ***\")\n",
    "        else:\n",
    "            epochs_no_improve += 1 # Val Loss æœªæ”¹å–„ï¼Œè¨ˆæ•¸å™¨ +1\n",
    "            print(f\"Val Loss æœªæ”¹å–„ (é€£çºŒ {epochs_no_improve} å€‹é€±æœŸæœªæ”¹å–„).\")\n",
    "\n",
    "        # æª¢æŸ¥æ˜¯å¦é”åˆ°è€å¿ƒä¸Šé™\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\nğŸš¨ğŸš¨ Early Stopping! Val Loss å·²é€£çºŒ {patience} å€‹é€±æœŸæœªæ”¹å–„ï¼Œåœæ­¢è¨“ç·´ã€‚ğŸš¨ğŸš¨\")\n",
    "            break # è·³å‡º Epoch è¿´åœˆ\n",
    "            \n",
    "    print(\"\\nè¨“ç·´æµç¨‹çµæŸã€‚\")\n",
    "\n",
    "\n",
    "# --- I. åŸ·è¡Œè¨“ç·´ (ä¿®æ­£å‘¼å«)\n",
    "if __name__ == '__main__':\n",
    "    baseline_model = build_baseline_model(NUM_CLASSES)\n",
    "    \n",
    "    # å‡è¨­æ‚¨å·²ç¶“å®šç¾©äº† NUM_EPOCHS, LEARNING_RATE, PATIENCE å¸¸æ•¸\n",
    "    train_and_save_model(baseline_model, train_loader, val_loader,\n",
    "                         num_epochs=EPOCHS,\n",
    "                         learning_rate=LEARNING_RATE,\n",
    "                         patience=PATIENCE) # å‚³å…¥ PATIENCE åƒæ•¸\n",
    "    \n",
    "    print(\"\\nâœ… è¨“ç·´å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d0b1c18-bc0d-4be2-8b7d-582a6b098a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:43:12.859482Z",
     "iopub.status.busy": "2025-11-19T10:43:12.858676Z",
     "iopub.status.idle": "2025-11-19T10:43:15.105502Z",
     "shell.execute_reply": "2025-11-19T10:43:15.103130Z",
     "shell.execute_reply.started": "2025-11-19T10:43:12.859417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extractor æ¸¬è©¦æˆåŠŸ ---\n",
      "æå–å‡ºçš„ç‰¹å¾µå‘é‡å½¢ç‹€ (Batch, Embedding_Dim): (32, 2048)\n",
      "âœ… Baseline ç‰¹å¾µæå–å™¨å·²æº–å‚™å°±ç·’ï¼\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# å€å¡Š 4ï¼šç‰¹å¾µæå–å™¨ (Extractor) å®šç¾©èˆ‡æ¸¬è©¦\n",
    "# =======================================================\n",
    "\n",
    "# ç¢ºä¿æ‰€æœ‰åƒæ•¸èˆ‡è¨“ç·´æ™‚ä¸€è‡´\n",
    "EMBEDDING_DIM = 2048    # ResNet50 å€’æ•¸ç¬¬äºŒå±¤è¼¸å‡ºç¶­åº¦\n",
    "WEIGHTS_SAVE_PATH = 'baseline_model.pth' # è¨“ç·´ç”¢ç”Ÿçš„æ¬Šé‡æª”æ¡ˆå\n",
    "DEVICE_EXTRACTOR = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# A. æ ¸å¿ƒå‡½æ•¸ï¼šè¼‰å…¥ç‰¹å¾µæå–å™¨\n",
    "# ----------------------------------------------------\n",
    "def load_embedding_extractor(weights_path: str = WEIGHTS_SAVE_PATH) -> nn.Module:\n",
    "    \"\"\"\n",
    "    è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡ï¼Œå°‡æ¨¡å‹è½‰æ›ç‚ºç‰¹å¾µæå–å™¨ (ç§»é™¤åˆ†é¡å±¤)ã€‚\n",
    "    \"\"\"\n",
    "    if not os.path.exists(weights_path):\n",
    "        raise FileNotFoundError(f\"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ¬Šé‡æª”æ¡ˆ {weights_path}ã€‚è«‹å…ˆå®Œæˆè¨“ç·´ã€‚\")\n",
    "        \n",
    "    # 1. å»ºç«‹èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„å®Œæ•´æ¨¡å‹çµæ§‹\n",
    "    # âš ï¸ é€™è£¡ä¸éœ€è¦ä¸‹è¼‰ weightsï¼Œå› ç‚ºæˆ‘å€‘å°‡è¼‰å…¥è‡ªå·±çš„æ¬Šé‡\n",
    "    model = resnet50(weights=None) \n",
    "    num_ftrs = model.fc.in_features\n",
    "    # æ›¿æ›ç‚ºè¨“ç·´æ™‚ä½¿ç”¨çš„åˆ†é¡å±¤\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "    # 2. è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡\n",
    "    model.load_state_dict(torch.load(weights_path, map_location='cpu'))\n",
    "    \n",
    "    # 3. è½‰æ›ç‚ºç‰¹å¾µæå–å™¨ï¼šå°‡åˆ†é¡å±¤æ›¿æ›ç‚º nn.Identity() (å³ 2048-dim ç‰¹å¾µè¼¸å‡º)\n",
    "    model.fc = nn.Identity()\n",
    "    \n",
    "    # 4. è¨­ç½®ç‚ºè©•ä¼°æ¨¡å¼\n",
    "    model.eval()\n",
    "    return model.to(DEVICE_EXTRACTOR)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# B. æå–ç‰¹å¾µå‡½æ•¸\n",
    "# ----------------------------------------------------\n",
    "def extract_features(extractor: nn.Module, image_tensor: torch.Tensor, normalize: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    å¾åœ–åƒå¼µé‡ä¸­æå–ç‰¹å¾µå‘é‡ï¼Œä¸¦å¯é¸ L2 æ­£è¦åŒ–ã€‚\n",
    "    \"\"\"\n",
    "    image_tensor = image_tensor.to(DEVICE_EXTRACTOR)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding = extractor(image_tensor)\n",
    "        \n",
    "        if normalize:\n",
    "            # æ¨è–¦å°ç‰¹å¾µé€²è¡Œ L2 æ­£è¦åŒ–ï¼Œä»¥ç¢ºä¿é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—çš„ç©©å®šæ€§\n",
    "            embedding = F.normalize(embedding, p=2, dim=1)\n",
    "        \n",
    "        return embedding.cpu().numpy() # è½‰æ›ç‚º numpy é™£åˆ—æ–¹ä¾¿å¾ŒçºŒä½¿ç”¨\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# C. æ¨¡æ“¬æ¸¬è©¦\n",
    "# ----------------------------------------------------\n",
    "try:\n",
    "    # 1. è¼‰å…¥ç‰¹å¾µæå–å™¨\n",
    "    extractor = load_embedding_extractor()\n",
    "    \n",
    "    # 2. å¾ val_loader å–ä¸€å€‹ batch é€²è¡Œæ¸¬è©¦\n",
    "    # é€™è£¡å‡è¨­ val_loader ä»ç„¶å¯ç”¨ï¼Œæˆ–è€…æ‚¨å¯ä»¥æ‰‹å‹•è¼‰å…¥ä¸€å¼µåœ–ç‰‡é€²è¡Œæ¸¬è©¦\n",
    "    images, _ = next(iter(val_loader)) \n",
    "    \n",
    "    # 3. æå–ç‰¹å¾µ\n",
    "    feature_vector = extract_features(extractor, images)\n",
    "    \n",
    "    print(\"\\n--- Extractor æ¸¬è©¦æˆåŠŸ ---\")\n",
    "    print(f\"æå–å‡ºçš„ç‰¹å¾µå‘é‡å½¢ç‹€ (Batch, Embedding_Dim): {feature_vector.shape}\")\n",
    "    print(\"âœ… Baseline ç‰¹å¾µæå–å™¨å·²æº–å‚™å°±ç·’ï¼\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Extractor æ¸¬è©¦å¤±æ•—: {e}\")\n",
    "    print(\"è«‹ç¢ºä¿ baseline_model.pth å­˜åœ¨ï¼Œä¸” val_loader è®Šæ•¸å¯ç”¨ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273880c2-4e18-4491-9834-07e89bd09db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:43:18.473523Z",
     "iopub.status.busy": "2025-11-19T10:43:18.472702Z",
     "iopub.status.idle": "2025-11-19T10:45:31.831303Z",
     "shell.execute_reply": "2025-11-19T10:45:31.830088Z",
     "shell.execute_reply.started": "2025-11-19T10:43:18.473453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é–‹å§‹æå– 13752 å¼µåœ–åƒçš„ç‰¹å¾µ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [00:45<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é–‹å§‹æå– 13752 å¼µåœ–åƒçš„ç‰¹å¾µ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430/430 [01:03<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Recall@K: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13752/13752 [00:15<00:00, 881.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Baseline æ¨¡å‹ Recall@K è©•ä¼°çµæœ ==========\n",
      "Recall@1: 0.9708\n",
      "Recall@5: 0.9946\n",
      "Recall@10: 0.9969\n",
      "Recall@20: 0.9982\n",
      "======================================================\n",
      "âœ… Baseline æª¢ç´¢è©•ä¼°å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# å€å¡Š 5ï¼šRecall@K è©•ä¼°\n",
    "# =======================================================\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# A. æå–æ‰€æœ‰ç‰¹å¾µ (Gallery Features)\n",
    "# ----------------------------------------------------\n",
    "def extract_all_features(data_loader: DataLoader, extractor: nn.Module) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"éæ­· DataLoaderï¼Œæå–æ‰€æœ‰åœ–åƒçš„ç‰¹å¾µå‘é‡å’Œå°æ‡‰æ¨™ç±¤ã€‚\"\"\"\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    extractor.eval()\n",
    "    \n",
    "    print(f\"é–‹å§‹æå– {len(data_loader.dataset)} å¼µåœ–åƒçš„ç‰¹å¾µ...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Extracting Features\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            \n",
    "            # ç²å– 2048 ç¶­ç‰¹å¾µ\n",
    "            features = extractor(inputs)\n",
    "            \n",
    "            # L2 æ­£è¦åŒ– (èˆ‡ extract_features å‡½æ•¸ä¸€è‡´)\n",
    "            features = F.normalize(features, p=2, dim=1) \n",
    "            \n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "# è¼‰å…¥æå–å™¨ (ç¢ºä¿å®ƒå·²ç¶“è¢«è¼‰å…¥åˆ°è¨˜æ†¶é«”ä¸­ï¼Œå¦‚æœæ²’æœ‰ï¼Œè«‹ä½¿ç”¨ load_embedding_extractor())\n",
    "if 'extractor' not in locals():\n",
    "    extractor = load_embedding_extractor() \n",
    "\n",
    "\n",
    "# æå– Gallery (åœ–åº«) ç‰¹å¾µï¼šä½¿ç”¨ val_loader çš„è³‡æ–™\n",
    "GALLERY_FEATURES, GALLERY_LABELS = extract_all_features(val_loader, extractor)\n",
    "\n",
    "# æå– Query (æŸ¥è©¢) ç‰¹å¾µï¼šé€šå¸¸ä½¿ç”¨ä¸€å€‹ç¨ç«‹çš„æŸ¥è©¢é›†ã€‚\n",
    "# ç”±æ–¼ In-shop æª¢ç´¢ä»»å‹™çš„ç‰¹æ®Šæ€§ï¼Œæˆ‘å€‘ä½¿ç”¨è¨“ç·´é›†ä½œç‚ºæŸ¥è©¢é›†\n",
    "QUERY_FEATURES, QUERY_LABELS = extract_all_features(train_loader, extractor)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# B. Recall@K è¨ˆç®—\n",
    "# ----------------------------------------------------\n",
    "def calculate_recall_at_k(query_features: np.ndarray, query_labels: np.ndarray, \n",
    "                          gallery_features: np.ndarray, gallery_labels: np.ndarray, \n",
    "                          ks: List[int]) -> dict:\n",
    "    \"\"\"è¨ˆç®— Recall@K æŒ‡æ¨™ã€‚\"\"\"\n",
    "    \n",
    "    # è¨ˆç®—æ‰€æœ‰ Query å° Gallery çš„é¤˜å¼¦ç›¸ä¼¼åº¦ (çŸ©é™£ä¹˜æ³•ï¼Œå› ç‚ºç‰¹å¾µå·²ç¶“ L2 æ­£è¦åŒ–)\n",
    "    print(\"\\nè¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...\")\n",
    "    # shape: (Num_Queries, Num_Gallery)\n",
    "    similarity_matrix = np.dot(query_features, gallery_features.T) \n",
    "    \n",
    "    recalls = {k: 0 for k in ks}\n",
    "    num_queries = len(query_labels)\n",
    "    \n",
    "    for i in tqdm(range(num_queries), desc=\"Calculating Recall@K\"):\n",
    "        q_label = query_labels[i]\n",
    "        \n",
    "        # ç²å–ç›¸ä¼¼åº¦åˆ†æ•¸ï¼Œä¸¦æ’åºç´¢å¼•\n",
    "        # æœ€é«˜çš„ç›¸ä¼¼åº¦åœ¨æœ€å‰é¢\n",
    "        # âš ï¸ é€™è£¡ä½¿ç”¨ argsort åå‘æ’åº\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1]\n",
    "        \n",
    "        # ç²å–æ’åºå¾Œçš„ Gallery æ¨™ç±¤\n",
    "        sorted_gallery_labels = gallery_labels[top_k_indices]\n",
    "        \n",
    "        # éæ¿¾æ‰æŸ¥è©¢åœ–åƒæœ¬èº« (å¦‚æœ Gallery åŒ…å« Query)\n",
    "        # ç”±æ–¼æ‚¨ä½¿ç”¨äº† train/val å…©å€‹ä¸åŒçš„ loaderï¼Œé€™è£¡å¯ä»¥å¿½ç•¥é€™ä¸€è¤‡é›œæ­¥é©Ÿ\n",
    "        \n",
    "        # æª¢æŸ¥ Recall@K\n",
    "        for k in ks:\n",
    "            if k > len(sorted_gallery_labels): continue\n",
    "            \n",
    "            # æª¢æŸ¥ top-K æª¢ç´¢çµæœä¸­ï¼Œæ˜¯å¦æœ‰èˆ‡ Query ç›¸åŒæ¨™ç±¤çš„åœ–åƒ\n",
    "            # (ä½†ä¸æ˜¯å®ƒè‡ªå·±ï¼Œå¦‚æœ train/val ä¸åˆ†é›¢å‰‡éœ€è¦æ’é™¤)\n",
    "            if np.any(sorted_gallery_labels[:k] == q_label):\n",
    "                recalls[k] += 1\n",
    "                \n",
    "    # å°‡è¨ˆæ•¸è½‰æ›ç‚ºæ¯”ä¾‹\n",
    "    recall_results = {f\"Recall@{k}\": count / num_queries for k, count in recalls.items()}\n",
    "    return recall_results\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# C. åŸ·è¡Œè©•ä¼°\n",
    "# ----------------------------------------------------\n",
    "K_VALUES = [1, 5, 10, 20] # æ¥­ç•Œå¸¸ç”¨ K å€¼\n",
    "\n",
    "recall_metrics = calculate_recall_at_k(\n",
    "    query_features=QUERY_FEATURES,\n",
    "    query_labels=QUERY_LABELS,\n",
    "    gallery_features=GALLERY_FEATURES,\n",
    "    gallery_labels=GALLERY_LABELS,\n",
    "    ks=K_VALUES\n",
    ")\n",
    "\n",
    "# è¼¸å‡ºçµæœ\n",
    "print(\"\\n========== Baseline æ¨¡å‹ Recall@K è©•ä¼°çµæœ ==========\")\n",
    "for k, score in recall_metrics.items():\n",
    "    print(f\"{k}: {score:.4f}\")\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"âœ… Baseline æª¢ç´¢è©•ä¼°å®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
